#!/usr/local/bin/ansible-playbook --inventory=inventory

- name: 'Extract backup file from etcd debugger node and store in S3'
  hosts: localhost
  vars:
    module: "store-backup-on-s3"
    ansible_name_module: " ETCD BACKUP | {{ module }}"

  tasks:
    - name: '{{ ansible_name_module }} | set_fact | variables from ENV'
      set_fact:
        bkp_staging_dir_on_controller: "{{ lookup('env', 'ETCD_BACKUP_DIR') }}"
        bkp_bundle_dir_on_controller: "{{ lookup('env', 'ETCD_BACKUP_BUNDLE_DIR') }}"
        bkp_bundle_file_prefix: "{{ lookup('env', 'ETCD_BACKUP_FILE_PREFIX') }}"
        s3_upload: "{{ lookup('env', 'ETCD_BACKUP_S3_UPLOAD') }}"
        bkp_playbook_dir: "{{ lookup('env', 'ETCD_BACKUP_PLAYBOOK_DIR') }}"

    - name: '{{ ansible_name_module }} | set_fact | Set bundle file name '
      set_fact:
        bkp_bundle_file_name: "{{ bkp_bundle_file_prefix }}-{{ lookup('pipe', 'date +%Y%m%d-%H%M') }}.gz"

    - name: '{{ ansible_name_module }} | find | list content of staging directory'
      find:
        path: "{{ bkp_staging_dir_on_controller }}"
        recurse: yes
      register: bk_file_list

    - name: '{{ ansible_name_module }} | find | list content of staging directory'
      set_fact:
        bundle_files_to_delete: "{{ bk_file_list | map(attribute='path') | list }}"

    - name: '{{ ansible_name_module }} | debug | Print list of backup files 1 of 2'
      debug:
        var: bk_file_list

    - name: '{{ ansible_name_module }} | debug | Print list of backup files 2 of 2'
      debug:
        var: bundle_files_to_delete 

    - name: '{{ ansible_name_module }} | archive | create backup bundle '
      archive:
        path: "{{ bkp_staging_dir_on_controller }}/*"
        dest: "{{ bkp_bundle_dir_on_controller }}/{{ bkp_bundle_file_name }}"
        format: gz

    - name: '{{ ansible_name_module }} | s3 | load backup file to s3'
      when:
        - s3_upload is defined
        - s3_upload | bool
      block:
        - name: '{{ ansible_name_module }} | s3 | install boto3'
          pip:
            name: boto3
            state: present
            extra_args: --user

        - name: '{{ ansible_name_module }} | s3 | load backup file to s3'
          aws_s3:
            aws_access_key: "{{ lookup('env','AWS_ACCESS_KEY') }}"
            aws_secret_key: "{{ lookup('env','AWS_KEY_SECRET') }}"
            bucket: "{{ lookup('env', 'AWS_BUCKET') }}"
            object: "{{ lookup('env', 'AWS_BUCKET_OBJECT') }}"
            src: "{{ bkp_bundle_dir_on_controller }}/{{ bkp_bundle_file_name }}"
            mode: put 
            overwrite: no
          register: aws_s3_loaded

        - name: '{{ ansible_name_module }} | debug | Print ouput of S3 file loading'
          debug:
            var: aws_s3_loaded

    - name: '{{ ansible_name_module }} | shell:rm  | clean up staging resources'
      file:
        path: "{{ item }}"
        state: absent
      when:
        - (s3_upload | d('false', true) | bool and aws_s3_loaded is defined and aws_s3_loaded.url is defined and aws_s3_loaded.url != '') or (clean_resources |d ('false', true) | bool ) 
      loop:
        #- "{{ bk_file_list.files }}"
        - "{{ bkp_bundle_dir_on_controller }}/{{ bkp_bundle_file_name }}"
      register: staging_resources_clean

